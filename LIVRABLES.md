# Livrables du Lab - RestTemplate vs Feign vs WebClient

## ğŸ“‹ Liste des livrables attendus

### 1. Code des 2 services (client + voiture) âœ…

**Service Voiture** :
- âœ… Code source complet dans `service-voiture/`
- âœ… Endpoint : `GET /api/cars/byClient/{clientId}`
- âœ… Configuration Eureka et Consul
- âœ… Actuator configurÃ© pour les mÃ©triques

**Service Client** :
- âœ… Code source complet dans `service-client/`
- âœ… 3 endpoints (RestTemplate, Feign, WebClient)
- âœ… Configuration Eureka et Consul
- âœ… Actuator configurÃ© pour les mÃ©triques

**Structure** :
```
service-voiture/
â”œâ”€â”€ controller/VoitureController.java
â”œâ”€â”€ service/VoitureService.java
â””â”€â”€ model/Voiture.java

service-client/
â”œâ”€â”€ controller/ClientController.java
â”œâ”€â”€ service/VoitureService.java
â”œâ”€â”€ feign/VoitureFeignClient.java
â””â”€â”€ config/RestTemplateConfig.java
```

### 2. Preuve d'enregistrement (capture Eureka/Consul) ğŸ“¸

#### Eureka

1. **DÃ©marrer Eureka Server** :
   ```bash
   cd eureka-server
   mvn spring-boot:run
   ```

2. **AccÃ©der Ã  l'UI Eureka** :
   - URL : http://localhost:8761
   - Capturer l'Ã©cran montrant :
     - Les services enregistrÃ©s : `SERVICE-VOITURE` et `SERVICE-CLIENT`
     - Leur statut (UP)
     - Leurs instances

3. **Exemple de capture attendue** :
   - Section "Instances currently registered with Eureka"
   - Liste des applications avec leurs instances

#### Consul

1. **DÃ©marrer Consul** :
   ```bash
   consul agent -dev
   ```

2. **DÃ©marrer les services avec profil Consul** :
   ```bash
   cd service-voiture
   mvn spring-boot:run -Dspring-boot.run.profiles=consul
   
   cd service-client
   mvn spring-boot:run -Dspring-boot.run.profiles=consul
   ```

3. **AccÃ©der Ã  l'UI Consul** :
   - URL : http://localhost:8500
   - Naviguer vers "Services"
   - Capturer l'Ã©cran montrant :
     - Les services : `service-voiture` et `service-client`
     - Leur statut (passing)
     - Leurs health checks

4. **Exemple de capture attendue** :
   - Liste des services avec statut "passing"
   - DÃ©tails des health checks

### 3. RÃ©sultats de tests (latence, dÃ©bit, CPU/RAM) ğŸ“Š

#### Tests de performance JMeter

**Tableau de rÃ©sultats - Latence et DÃ©bit** :

| MÃ©thode | Threads | Temps moyen (ms) | P95 (ms) | DÃ©bit (req/s) | Taux d'erreur (%) |
|---------|---------|------------------|----------|---------------|-------------------|
| RestTemplate | 10 | | | | |
| RestTemplate | 50 | | | | |
| RestTemplate | 100 | | | | |
| RestTemplate | 200 | | | | |
| RestTemplate | 500 | | | | |
| Feign | 10 | | | | |
| Feign | 50 | | | | |
| Feign | 100 | | | | |
| Feign | 200 | | | | |
| Feign | 500 | | | | |
| WebClient | 10 | | | | |
| WebClient | 50 | | | | |
| WebClient | 100 | | | | |
| WebClient | 200 | | | | |
| WebClient | 500 | | | | |

**Tableau de rÃ©sultats - CPU et MÃ©moire** :

| MÃ©thode | Threads | CPU Max (%) | RAM Max (MB) | CPU Moyen (%) | RAM Moyen (MB) |
|---------|---------|-------------|--------------|---------------|----------------|
| RestTemplate | 10 | | | | |
| RestTemplate | 50 | | | | |
| RestTemplate | 100 | | | | |
| RestTemplate | 200 | | | | |
| RestTemplate | 500 | | | | |
| Feign | 10 | | | | |
| Feign | 50 | | | | |
| Feign | 100 | | | | |
| Feign | 200 | | | | |
| Feign | 500 | | | | |
| WebClient | 10 | | | | |
| WebClient | 50 | | | | |
| WebClient | 100 | | | | |
| WebClient | 200 | | | | |
| WebClient | 500 | | | | |

**Note** : SÃ©parer les mesures pour Service Voiture et Service Client si nÃ©cessaire.

#### Fichiers de rÃ©sultats JMeter

- Sauvegarder les fichiers `.jtl` gÃ©nÃ©rÃ©s par JMeter
- Sauvegarder les rapports HTML gÃ©nÃ©rÃ©s
- Organiser dans un dossier `results/` :
  ```
  results/
  â”œâ”€â”€ resttemplate_10threads_20240101_120000.jtl
  â”œâ”€â”€ resttemplate_10threads_20240101_120000_report/
  â”œâ”€â”€ feign_10threads_20240101_120500.jtl
  â””â”€â”€ ...
  ```

### 4. Analyse comparÃ©e (1-2 pages) ğŸ“

#### Structure recommandÃ©e de l'analyse

**1. Introduction** (1 paragraphe)
- Contexte du lab
- Objectifs de la comparaison

**2. MÃ©thodologie** (1 paragraphe)
- Environnement de test (OS, Java version, etc.)
- Charges testÃ©es
- Outils utilisÃ©s (JMeter, Task Manager, etc.)

**3. RÃ©sultats de performance** (2-3 paragraphes)
- Comparaison des latences
- Comparaison des dÃ©bits
- Analyse des diffÃ©rences observÃ©es

**4. Consommation de ressources** (1-2 paragraphes)
- Comparaison CPU
- Comparaison mÃ©moire
- Impact sur la scalabilitÃ©

**5. Avantages et inconvÃ©nients** (1 paragraphe)
- RestTemplate : points forts/faibles
- Feign : points forts/faibles
- WebClient : points forts/faibles

**6. Conclusion** (1 paragraphe)
- Recommandations selon les cas d'usage
- MÃ©thode la plus performante dans ce contexte
- MÃ©thode la plus adaptÃ©e selon les besoins

#### Exemple de structure dÃ©taillÃ©e

```markdown
# Analyse ComparÃ©e : RestTemplate vs Feign vs WebClient

## 1. Introduction
[Contexte et objectifs]

## 2. MÃ©thodologie
- Environnement : Windows 10, Java 17, Spring Boot 3.2.0
- Tests : JMeter avec 10, 50, 100, 200, 500 threads
- Mesures : Latence, dÃ©bit, CPU, RAM

## 3. RÃ©sultats de Performance

### 3.1 Latence
[Analyse des temps de rÃ©ponse moyens et P95]

### 3.2 DÃ©bit
[Analyse des requÃªtes par seconde]

## 4. Consommation de Ressources

### 4.1 CPU
[Comparaison de l'utilisation CPU]

### 4.2 MÃ©moire
[Comparaison de l'utilisation mÃ©moire]

## 5. Comparaison des MÃ©thodes

### 5.1 RestTemplate
- Avantages : [simplicitÃ©, compatibilitÃ©]
- InconvÃ©nients : [bloquant, maintenance mode]

### 5.2 Feign
- Avantages : [dÃ©claratif, lisibilitÃ©]
- InconvÃ©nients : [overhead, compilation]

### 5.3 WebClient
- Avantages : [rÃ©actif, non-bloquant]
- InconvÃ©nients : [complexitÃ©, courbe d'apprentissage]

## 6. Conclusion
[Recommandations et synthÃ¨se]
```

## ğŸ“ Organisation des livrables

CrÃ©er un dossier `livrables/` avec :

```
livrables/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ service-voiture/
â”‚   â””â”€â”€ service-client/
â”œâ”€â”€ captures/
â”‚   â”œâ”€â”€ eureka-services.png
â”‚   â”œâ”€â”€ consul-services.png
â”‚   â””â”€â”€ consul-health-checks.png
â”œâ”€â”€ resultats/
â”‚   â”œâ”€â”€ performance-latence-debit.csv
â”‚   â”œâ”€â”€ performance-cpu-ram.csv
â”‚   â”œâ”€â”€ jmeter-results/
â”‚   â””â”€â”€ graphs/
â””â”€â”€ analyse/
    â””â”€â”€ analyse-comparee.md
```

## âœ… Checklist de validation

- [ ] Code source des 2 services complet et fonctionnel
- [ ] Capture d'Ã©cran Eureka montrant les services enregistrÃ©s
- [ ] Capture d'Ã©cran Consul montrant les services enregistrÃ©s
- [ ] Tableau de rÃ©sultats de performance (latence, dÃ©bit)
- [ ] Tableau de rÃ©sultats de ressources (CPU, RAM)
- [ ] Fichiers de rÃ©sultats JMeter sauvegardÃ©s
- [ ] Analyse comparÃ©e rÃ©digÃ©e (1-2 pages)
- [ ] Graphiques de comparaison (optionnel mais recommandÃ©)

## ğŸ“Š Outils pour crÃ©er les graphiques

- **Excel/Google Sheets** : Pour les tableaux et graphiques simples
- **Python (matplotlib)** : Pour des graphiques plus avancÃ©s
- **Grafana** : Si Prometheus est utilisÃ©
- **JMeter HTML Report** : Rapports gÃ©nÃ©rÃ©s automatiquement

## ğŸ’¡ Conseils pour l'analyse

1. **ÃŠtre objectif** : PrÃ©senter les faits, pas seulement les prÃ©fÃ©rences
2. **Contextualiser** : Expliquer pourquoi certaines diffÃ©rences existent
3. **Visualiser** : Utiliser des graphiques pour rendre l'analyse plus claire
4. **Conclure** : Donner des recommandations pratiques selon les cas d'usage
